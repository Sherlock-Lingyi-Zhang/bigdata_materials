{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Lab 7: Using Spark MLlib for Feature Engineering and Prediction\n",
    "\n",
    "\n",
    "This lab focuses on building a ML pipeline with focus on feature data exploration and feature engineering. It has two parts:\n",
    "\n",
    "- Part 1 `Concrete Quality`: we focus on doing column statistics and engineering numerical features \n",
    "- Part 2 `Car Value`: we focus on engineering string columns.\n",
    "\n",
    "\n",
    "**Topics**: `describe, VectorAssembler, StandardScaler, Pipeline, StringIndexer, DecisionTreeClassifier, MulticlassClassificationEvaluator`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Tip**:If at any point you see this error, `AnalysisException: u'java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient;`. \n",
    "\n",
    "Please\n",
    "- removing the *.lck file from hive `metastore_db`\n",
    "```\n",
    "# assuming you're running this from your home directory from cloudera vm\n",
    "rm  metastore_db/*.lck\n",
    "```\n",
    "- Terminate all other running jupyter notebooks (from your jupyter home, go to Running tab, then terminate). \n",
    "\n",
    "If the above does not work still, try to restart the kernel (from your current jupyter notebook's menu, kernel > restart).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "\n",
    "1\\. Download and unzip the data files needed for this lab from \n",
    "\n",
    "[http://idsdl.csom.umn.edu/c/share/sparklab07data.zip](http://idsdl.csom.umn.edu/c/share/sparklab07data.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Prepare Concrete Quality Dataset for Spark MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the lab uses adataset regarding the various properties and strength of concrete. Please complete the lab using `spark.ml` API functions. \n",
    "\n",
    "#|Field Name|Type| Description\n",
    "--|--|--|--\n",
    "0|cement|Double|Mass, in kg per cubic meter of mixture\n",
    "1|blast_furnace_slag|Double|Mass, in kg per cubic meter of mixture\n",
    "2|fly_ash|Double|Mass, in kg per cubic meter of mixture\n",
    "3|water|Double|Mass, in kg per cubic meter of mixture\n",
    "4|superplasticizer|Double|Mass, in kg per cubic meter of mixture\n",
    "5|course_aggregate|Double|Mass, in kg per cubic meter of mixture\n",
    "6|fine_aggregate|Double|Mass, in kg per cubic meter of mixture\n",
    "7|age|Double|Age, in days\n",
    "8|compressive_strength|Double|Strength, in megapascals (MPa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Sample the first few lines of `concrete_train.csv` using linux command(s), which helps you decide how to handle this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540.0,0.0,0.0,162.0,2.5,1040.0,676.0,28,79.99\r",
      "\r\n",
      "540.0,0.0,0.0,162.0,2.5,1055.0,676.0,28,61.89\r",
      "\r\n",
      "332.5,142.5,0.0,228.0,0.0,932.0,594.0,270,40.27\r",
      "\r\n",
      "332.5,142.5,0.0,228.0,0.0,932.0,594.0,365,41.05\r",
      "\r\n",
      "198.6,132.4,0.0,192.0,0.0,978.4,825.5,360,44.30\r",
      "\r\n",
      "266.0,114.0,0.0,228.0,0.0,932.0,670.0,90,47.03\r",
      "\r\n",
      "380.0,95.0,0.0,228.0,0.0,932.0,594.0,365,43.70\r",
      "\r\n",
      "380.0,95.0,0.0,228.0,0.0,932.0,594.0,28,36.45\r",
      "\r\n",
      "266.0,114.0,0.0,228.0,0.0,932.0,670.0,28,45.85\r",
      "\r\n",
      "475.0,0.0,0.0,228.0,0.0,932.0,594.0,28,39.29\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# You path may be different from the one shown below.\n",
    "! head concrete_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Load the `concrete_train.csv` file into a dataframe. Verify its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = [\"cement\",\"blast_furnace_slag\",\"fly_ash\",\"water\", \\\n",
    "          \"superplasticizer\",\"course_aggregate\",\"fine_aggregate\", \\\n",
    "         \"age\",\"compressive_strength\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You path may be different. \n",
    "train = spark.read.option(\"inferSchema\",True).csv(\"concrete_train.csv\").toDF(*fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cement: double (nullable = true)\n",
      " |-- blast_furnace_slag: double (nullable = true)\n",
      " |-- fly_ash: double (nullable = true)\n",
      " |-- water: double (nullable = true)\n",
      " |-- superplasticizer: double (nullable = true)\n",
      " |-- course_aggregate: double (nullable = true)\n",
      " |-- fine_aggregate: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- compressive_strength: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------+-----+----------------+----------------+--------------+---+--------------------+\n",
      "|cement|blast_furnace_slag|fly_ash|water|superplasticizer|course_aggregate|fine_aggregate|age|compressive_strength|\n",
      "+------+------------------+-------+-----+----------------+----------------+--------------+---+--------------------+\n",
      "| 540.0|               0.0|    0.0|162.0|             2.5|          1040.0|         676.0| 28|               79.99|\n",
      "| 540.0|               0.0|    0.0|162.0|             2.5|          1055.0|         676.0| 28|               61.89|\n",
      "| 332.5|             142.5|    0.0|228.0|             0.0|           932.0|         594.0|270|               40.27|\n",
      "| 332.5|             142.5|    0.0|228.0|             0.0|           932.0|         594.0|365|               41.05|\n",
      "| 198.6|             132.4|    0.0|192.0|             0.0|           978.4|         825.5|360|                44.3|\n",
      "| 266.0|             114.0|    0.0|228.0|             0.0|           932.0|         670.0| 90|               47.03|\n",
      "| 380.0|              95.0|    0.0|228.0|             0.0|           932.0|         594.0|365|                43.7|\n",
      "| 380.0|              95.0|    0.0|228.0|             0.0|           932.0|         594.0| 28|               36.45|\n",
      "| 266.0|             114.0|    0.0|228.0|             0.0|           932.0|         670.0| 28|               45.85|\n",
      "| 475.0|               0.0|    0.0|228.0|             0.0|           932.0|         594.0| 28|               39.29|\n",
      "| 198.6|             132.4|    0.0|192.0|             0.0|           978.4|         825.5| 90|               38.07|\n",
      "| 198.6|             132.4|    0.0|192.0|             0.0|           978.4|         825.5| 28|               28.02|\n",
      "| 427.5|              47.5|    0.0|228.0|             0.0|           932.0|         594.0|270|               43.01|\n",
      "| 190.0|             190.0|    0.0|228.0|             0.0|           932.0|         670.0| 90|               42.33|\n",
      "| 304.0|              76.0|    0.0|228.0|             0.0|           932.0|         670.0| 28|               47.81|\n",
      "| 380.0|               0.0|    0.0|228.0|             0.0|           932.0|         670.0| 90|               52.91|\n",
      "| 139.6|             209.4|    0.0|192.0|             0.0|          1047.0|         806.9| 90|               39.36|\n",
      "| 342.0|              38.0|    0.0|228.0|             0.0|           932.0|         670.0|365|               56.14|\n",
      "| 380.0|              95.0|    0.0|228.0|             0.0|           932.0|         594.0| 90|               40.56|\n",
      "| 475.0|               0.0|    0.0|228.0|             0.0|           932.0|         594.0|180|               42.62|\n",
      "+------+------------------+-------+-----+----------------+----------------+--------------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Because this dataset has numerical columns, it is useful to conduct summary statistics on it. Report the descriptive statistics\n",
    "\n",
    "**You may convert a DataFrame to pandas dataframe using `.toPandas()` for better readability.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>course_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>290.563222222222</td>\n",
       "      <td>68.4981111111111</td>\n",
       "      <td>49.03222222222221</td>\n",
       "      <td>180.72266666666667</td>\n",
       "      <td>5.810888888888885</td>\n",
       "      <td>981.0683333333328</td>\n",
       "      <td>776.2333333333324</td>\n",
       "      <td>48.21333333333333</td>\n",
       "      <td>36.37484444444442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>104.64460120499344</td>\n",
       "      <td>85.81753820138678</td>\n",
       "      <td>61.89869603838202</td>\n",
       "      <td>21.761715870809034</td>\n",
       "      <td>6.173544447428106</td>\n",
       "      <td>75.5029483066943</td>\n",
       "      <td>81.38528207195104</td>\n",
       "      <td>67.20007349431862</td>\n",
       "      <td>17.210366992350007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>540.0</td>\n",
       "      <td>359.4</td>\n",
       "      <td>200.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>992.6</td>\n",
       "      <td>365</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary              cement blast_furnace_slag            fly_ash  \\\n",
       "0   count                 900                900                900   \n",
       "1    mean    290.563222222222   68.4981111111111  49.03222222222221   \n",
       "2  stddev  104.64460120499344  85.81753820138678  61.89869603838202   \n",
       "3     min               102.0                0.0                0.0   \n",
       "4     max               540.0              359.4              200.0   \n",
       "\n",
       "                water   superplasticizer   course_aggregate  \\\n",
       "0                 900                900                900   \n",
       "1  180.72266666666667  5.810888888888885  981.0683333333328   \n",
       "2  21.761715870809034  6.173544447428106   75.5029483066943   \n",
       "3               121.8                0.0              801.0   \n",
       "4               247.0               32.2             1145.0   \n",
       "\n",
       "      fine_aggregate                age compressive_strength  \n",
       "0                900                900                  900  \n",
       "1  776.2333333333324  48.21333333333333    36.37484444444442  \n",
       "2  81.38528207195104  67.20007349431862   17.210366992350007  \n",
       "3              594.0                  1                 2.33  \n",
       "4              992.6                365                 82.6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`SQLTransformer(statement=...)`](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.SQLTransformer) implements the transforms which are defined by SQL statement. \n",
    "\n",
    "Currently it only supports SQL syntax like `\"SELECT … FROM __THIS__\"` where `__THIS__` represents the underlying table of the input dataset.\n",
    "\n",
    "4\\. Define a SQLTransformer `st` that creates a new field `age_enc` that takes the following values:\n",
    "\n",
    "- 1, if age is between 0 and 30\n",
    "- 2, if age is > 30 and <= 90\n",
    "- 3, if age is > 90 and <= 180\n",
    "- 4, if age is 180 and above\n",
    "\n",
    "Click the above link to see the documentation/example of this API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "st = SQLTransformer(statement=\"\"\"\n",
    "select *, case when age between 0 and 30 then 1 \n",
    "when (age > 30 and age <=90) then 2 \n",
    "when (age>90 and age<=180) then 3 \n",
    "else 4 end as age_enc\n",
    "from __THIS__\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_st = st.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>course_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>compressive_strength</th>\n",
       "      <th>age_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "5   266.0               114.0      0.0  228.0               0.0   \n",
       "6   380.0                95.0      0.0  228.0               0.0   \n",
       "7   380.0                95.0      0.0  228.0               0.0   \n",
       "8   266.0               114.0      0.0  228.0               0.0   \n",
       "9   475.0                 0.0      0.0  228.0               0.0   \n",
       "\n",
       "   course_aggregate  fine_aggregate  age  compressive_strength  age_enc  \n",
       "0            1040.0           676.0   28                 79.99        1  \n",
       "1            1055.0           676.0   28                 61.89        1  \n",
       "2             932.0           594.0  270                 40.27        4  \n",
       "3             932.0           594.0  365                 41.05        4  \n",
       "4             978.4           825.5  360                 44.30        4  \n",
       "5             932.0           670.0   90                 47.03        2  \n",
       "6             932.0           594.0  365                 43.70        4  \n",
       "7             932.0           594.0   28                 36.45        1  \n",
       "8             932.0           670.0   28                 45.85        1  \n",
       "9             932.0           594.0   28                 39.29        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_st.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Use [`VectorAssembler`](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler) to create a new `features` column with all fields except `compressive_strength` and `age`. \n",
    "\n",
    "If needed, click the link above to see an example from the official pyspark documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureCols = ['cement',\n",
    " 'blast_furnace_slag',\n",
    " 'fly_ash',\n",
    " 'water',\n",
    " 'superplasticizer',\n",
    " 'course_aggregate',\n",
    " 'fine_aggregate',\n",
    " 'age_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=featureCols,outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify your assembler does what it needs to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_va = assembler.transform(train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>course_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>compressive_strength</th>\n",
       "      <th>age_enc</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "      <td>1</td>\n",
       "      <td>[540.0, 0.0, 0.0, 162.0, 2.5, 1040.0, 676.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "      <td>1</td>\n",
       "      <td>[540.0, 0.0, 0.0, 162.0, 2.5, 1055.0, 676.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "      <td>4</td>\n",
       "      <td>[332.5, 142.5, 0.0, 228.0, 0.0, 932.0, 594.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "\n",
       "   course_aggregate  fine_aggregate  age  compressive_strength  age_enc  \\\n",
       "0            1040.0           676.0   28                 79.99        1   \n",
       "1            1055.0           676.0   28                 61.89        1   \n",
       "2             932.0           594.0  270                 40.27        4   \n",
       "\n",
       "                                            features  \n",
       "0  [540.0, 0.0, 0.0, 162.0, 2.5, 1040.0, 676.0, 1.0]  \n",
       "1  [540.0, 0.0, 0.0, 162.0, 2.5, 1055.0, 676.0, 1.0]  \n",
       "2  [332.5, 142.5, 0.0, 228.0, 0.0, 932.0, 594.0, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_va.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler` transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean. It takes parameters:\n",
    "\n",
    "- `withStd`: True by default. Scales the data to unit standard deviation.\n",
    "- `withMean`: False by default. Centers the data with mean before scaling. It will build a dense output, so take care when applying to sparse input.\n",
    "\n",
    "6\\. Create an instance of [`StandardScaler`](https://spark.apache.org/docs/latest/ml-features.html#standardscaler) called `ss`\n",
    "\n",
    "- it should apply to `features` and create a new column `scaledfeatures`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler(inputCol=\"features\", outputCol=\"scaledfeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify your standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ss = ss.fit(train_va).transform(train_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>course_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>compressive_strength</th>\n",
       "      <th>age_enc</th>\n",
       "      <th>features</th>\n",
       "      <th>scaledfeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "      <td>1</td>\n",
       "      <td>[540.0, 0.0, 0.0, 162.0, 2.5, 1040.0, 676.0, 1.0]</td>\n",
       "      <td>[5.16032355021, 0.0, 0.0, 7.44426592837, 0.404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "      <td>1</td>\n",
       "      <td>[540.0, 0.0, 0.0, 162.0, 2.5, 1055.0, 676.0, 1.0]</td>\n",
       "      <td>[5.16032355021, 0.0, 0.0, 7.44426592837, 0.404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "      <td>4</td>\n",
       "      <td>[332.5, 142.5, 0.0, 228.0, 0.0, 932.0, 594.0, ...</td>\n",
       "      <td>[3.17742144527, 1.66049974151, 0.0, 10.4771150...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "\n",
       "   course_aggregate  fine_aggregate  age  compressive_strength  age_enc  \\\n",
       "0            1040.0           676.0   28                 79.99        1   \n",
       "1            1055.0           676.0   28                 61.89        1   \n",
       "2             932.0           594.0  270                 40.27        4   \n",
       "\n",
       "                                            features  \\\n",
       "0  [540.0, 0.0, 0.0, 162.0, 2.5, 1040.0, 676.0, 1.0]   \n",
       "1  [540.0, 0.0, 0.0, 162.0, 2.5, 1055.0, 676.0, 1.0]   \n",
       "2  [332.5, 142.5, 0.0, 228.0, 0.0, 932.0, 594.0, ...   \n",
       "\n",
       "                                      scaledfeatures  \n",
       "0  [5.16032355021, 0.0, 0.0, 7.44426592837, 0.404...  \n",
       "1  [5.16032355021, 0.0, 0.0, 7.44426592837, 0.404...  \n",
       "2  [3.17742144527, 1.66049974151, 0.0, 10.4771150...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ss.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Create an instance of [`Pipeline`](https://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline) called `pl`\n",
    "\n",
    "-  Its `stages` should include the SQLTransformer, VectorAssembler and StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl = Pipeline(stages=[st, assembler,ss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Use the `Pipeline` to transform the data and obtain a new dataframe, `transformed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed = pl.fit(train).transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect `scaledFeatures` and `features` column in the transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([540.0, 0.0, 0.0, 162.0, 2.5, 1040.0, 676.0, 1.0]), scaledfeatures=DenseVector([5.1603, 0.0, 0.0, 7.4443, 0.405, 13.7743, 8.3062, 1.1955])),\n",
       " Row(features=DenseVector([540.0, 0.0, 0.0, 162.0, 2.5, 1055.0, 676.0, 1.0]), scaledfeatures=DenseVector([5.1603, 0.0, 0.0, 7.4443, 0.405, 13.973, 8.3062, 1.1955])),\n",
       " Row(features=DenseVector([332.5, 142.5, 0.0, 228.0, 0.0, 932.0, 594.0, 4.0]), scaledfeatures=DenseVector([3.1774, 1.6605, 0.0, 10.4771, 0.0, 12.3439, 7.2986, 4.7821])),\n",
       " Row(features=DenseVector([332.5, 142.5, 0.0, 228.0, 0.0, 932.0, 594.0, 4.0]), scaledfeatures=DenseVector([3.1774, 1.6605, 0.0, 10.4771, 0.0, 12.3439, 7.2986, 4.7821])),\n",
       " Row(features=DenseVector([198.6, 132.4, 0.0, 192.0, 0.0, 978.4, 825.5, 4.0]), scaledfeatures=DenseVector([1.8979, 1.5428, 0.0, 8.8228, 0.0, 12.9584, 10.1431, 4.7821]))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed.select(\"features\",\"scaledfeatures\").limit(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Using Decision Tree Classifiers to Predict Car Value\n",
    "\n",
    "During this exercise, you will build a Spark ML Pipeline to encode categorical string variables as integers before using them to build a model. \n",
    "\n",
    "The data used for this exercise concerns various properties of cars, and whether or not these cars were\n",
    "classified as a good value. The target value to be predictive is `acceptability`, which is a categorical variable representing whether or not a car is considered acceptable for purchase. All other feature variables are also **categorical**.\n",
    "\n",
    "#|Field|Data Type |Description\n",
    "--|--|--|--\n",
    "0|buying|String|Based on selling price\n",
    "1|maint|String|Based on cost to maintain the vehicle\n",
    "2|doors|String|Number of doors\n",
    "3|persons|String|Passenger capacity\n",
    "4|lug_boot|String|Based on luggage boot size\n",
    "5|safety|String|Based on estimated safety of the vehicle\n",
    "6|acceptability|String|Based on overall acceptability of the vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Begin by importing the necessary modules for this exercise.\n",
    "\n",
    "If you’re using the Scala, you’ll use this code:\n",
    "```\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.feature.{StringIndexer,VectorAssembler}\n",
    "import org.apache.spark.ml.classification.DecisionTreeClassifier\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "```\n",
    "If you’re using the the PySpark, you’ll use this code:\n",
    "```\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Sample the first few lines of `cars_train.csv` using linux command(s), which helps you decide how to handle this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vhigh,vhigh,2,2,small,low,unacc\r\n",
      "vhigh,vhigh,2,2,small,med,unacc\r\n",
      "vhigh,vhigh,2,2,small,high,unacc\r\n",
      "vhigh,vhigh,2,2,med,low,unacc\r\n",
      "vhigh,vhigh,2,2,med,med,unacc\r\n",
      "vhigh,vhigh,2,2,med,high,unacc\r\n",
      "vhigh,vhigh,2,2,big,low,unacc\r\n",
      "vhigh,vhigh,2,2,big,med,unacc\r\n",
      "vhigh,vhigh,2,2,big,high,unacc\r\n",
      "vhigh,vhigh,2,4,small,low,unacc\r\n"
     ]
    }
   ],
   "source": [
    "# your path may vary, default is cars_train.csv\n",
    "!head cars_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Load the `cars_train.csv` file into a DataFrame named `train_df`. Verify its schema & content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_str=\"\"\"\n",
    "    buying string, maint string, doors string, persons string, \n",
    "    lug_boot string, safety string, acceptability string\n",
    "\"\"\"\n",
    "train_df = spark.read.csv(\"cars_train.csv\",schema=schema_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- buying: string (nullable = true)\n",
      " |-- maint: string (nullable = true)\n",
      " |-- doors: string (nullable = true)\n",
      " |-- persons: string (nullable = true)\n",
      " |-- lug_boot: string (nullable = true)\n",
      " |-- safety: string (nullable = true)\n",
      " |-- acceptability: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Map `rawdata` to a new RDD of Scala arrays or Python lists called `lrdd` by splitting on commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-------+--------+------+-------------+\n",
      "|buying|maint|doors|persons|lug_boot|safety|acceptability|\n",
      "+------+-----+-----+-------+--------+------+-------------+\n",
      "| vhigh|vhigh|    2|      2|   small|   low|        unacc|\n",
      "| vhigh|vhigh|    2|      2|   small|   med|        unacc|\n",
      "| vhigh|vhigh|    2|      2|   small|  high|        unacc|\n",
      "| vhigh|vhigh|    2|      2|     med|   low|        unacc|\n",
      "| vhigh|vhigh|    2|      2|     med|   med|        unacc|\n",
      "| vhigh|vhigh|    2|      2|     med|  high|        unacc|\n",
      "| vhigh|vhigh|    2|      2|     big|   low|        unacc|\n",
      "| vhigh|vhigh|    2|      2|     big|   med|        unacc|\n",
      "| vhigh|vhigh|    2|      2|     big|  high|        unacc|\n",
      "| vhigh|vhigh|    2|      4|   small|   low|        unacc|\n",
      "| vhigh|vhigh|    2|      4|   small|   med|        unacc|\n",
      "| vhigh|vhigh|    2|      4|   small|  high|        unacc|\n",
      "| vhigh|vhigh|    2|      4|     med|   low|        unacc|\n",
      "| vhigh|vhigh|    2|      4|     med|   med|        unacc|\n",
      "| vhigh|vhigh|    2|      4|     med|  high|        unacc|\n",
      "| vhigh|vhigh|    2|      4|     big|   low|        unacc|\n",
      "| vhigh|vhigh|    2|      4|     big|   med|        unacc|\n",
      "| vhigh|vhigh|    2|      4|     big|  high|        unacc|\n",
      "| vhigh|vhigh|    2|   more|   small|   low|        unacc|\n",
      "| vhigh|vhigh|    2|   more|   small|   med|        unacc|\n",
      "+------+-----+-----+-------+--------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Explore the `buying`, `doors`,`persons`,`acceptability` columns by showing their distinct values. What kinds of columns are these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|buying|\n",
      "+------+\n",
      "|   low|\n",
      "| vhigh|\n",
      "|   med|\n",
      "|  high|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select(\"buying\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|doors|\n",
      "+-----+\n",
      "|    3|\n",
      "|    4|\n",
      "|5more|\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select(\"doors\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|persons|\n",
      "+-------+\n",
      "|   more|\n",
      "|      4|\n",
      "|      2|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select(\"persons\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|acceptability|\n",
      "+-------------+\n",
      "|        unacc|\n",
      "|          acc|\n",
      "|        vgood|\n",
      "|         good|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select(\"acceptability\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are categorical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Create a new [`StringIndexer`](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.StringIndexer) for each of the columns, with the output column name in the form of `[colname]_ix` (for example, `buying` becomes `buying_ix`). Save these seven StringIndexers as `si1`, `si2`, `si3`, and so on.\n",
    "\n",
    "**Note**: the default sort order of `StringIndexer` is `frequencyDesc`, others include `frequencyAsc, alphabetDesc, alphabetAsc`. See the above link and click source to see more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "si1 = StringIndexer(inputCol='buying',outputCol='buying_ix')\n",
    "si2 = StringIndexer(inputCol='maint',outputCol='maint_ix')\n",
    "si3 = StringIndexer(inputCol='doors',outputCol='doors_ix')\n",
    "si4 = StringIndexer(inputCol='persons',outputCol='persons_ix')\n",
    "si5 = StringIndexer(inputCol='lug_boot',outputCol='lug_boot_ix')\n",
    "si6 = StringIndexer(inputCol='safety',outputCol='safety_ix')\n",
    "si7 = StringIndexer(inputCol='acceptability',outputCol='acceptability_ix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Next, create a `VectorAssembler` called `va` to assemble each of the indexed columns **except `accetability_ix`** into a new column called `features`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexedcols = [\"buying_ix\",\"maint_ix\",\"doors_ix\",\"persons_ix\",\"lug_boot_ix\",\"safety_ix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=indexedcols,outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Create a `DecisionTreeClassifier` \n",
    "\n",
    "- the label column should be `acceacceptability_ix` \n",
    "- the features column should be `features`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol='features',labelCol='acceptability_ix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Create a new Spark ML `Pipeline` called `pl` \n",
    "\n",
    "- the `steps` should include all of the `StringIndexer`s,  the `VectorAssembler`, and the `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl = Pipeline(stages=[si1,si2, si3, si4, si5, si6, si7, va, dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Create a PipelineModel named `plmodel` by fitting the pipeline on `train_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plmodel = pl.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Create a new DataFrame called `test_df` from the `cars_test.csv` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = spark.read.csv(\"cars_test.csv\",schema=schema_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12\\. Applied the learned model on `test_df` and save the resultant DataFrame as `predictions`. \n",
    "\n",
    "- How many of the first 15 values in the `prediction` column match the values in the `acceptability_ix` column?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = plmodel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>buying_ix</th>\n",
       "      <th>maint_ix</th>\n",
       "      <th>doors_ix</th>\n",
       "      <th>persons_ix</th>\n",
       "      <th>lug_boot_ix</th>\n",
       "      <th>safety_ix</th>\n",
       "      <th>acceptability_ix</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 1.0, 2.0, 2.0]</td>\n",
       "      <td>[332.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 1.0, 2.0, 1.0]</td>\n",
       "      <td>[9.0, 122.0, 23.0, 0.0]</td>\n",
       "      <td>[0.0584415584416, 0.792207792208, 0.1493506493...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 1.0, 2.0, 0.0]</td>\n",
       "      <td>[9.0, 122.0, 23.0, 0.0]</td>\n",
       "      <td>[0.0584415584416, 0.792207792208, 0.1493506493...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 0.0, 2.0]</td>\n",
       "      <td>[332.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 0.0, 1.0]</td>\n",
       "      <td>[31.0, 47.0, 0.0, 0.0]</td>\n",
       "      <td>[0.397435897436, 0.602564102564, 0.0, 0.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 0.0, 0.0]</td>\n",
       "      <td>[31.0, 47.0, 0.0, 0.0]</td>\n",
       "      <td>[0.397435897436, 0.602564102564, 0.0, 0.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 1.0, 2.0]</td>\n",
       "      <td>[332.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 1.0, 1.0]</td>\n",
       "      <td>[9.0, 122.0, 23.0, 0.0]</td>\n",
       "      <td>[0.0584415584416, 0.792207792208, 0.1493506493...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 1.0, 0.0]</td>\n",
       "      <td>[9.0, 122.0, 23.0, 0.0]</td>\n",
       "      <td>[0.0584415584416, 0.792207792208, 0.1493506493...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 2.0, 2.0]</td>\n",
       "      <td>[332.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 2.0, 1.0]</td>\n",
       "      <td>[9.0, 122.0, 23.0, 0.0]</td>\n",
       "      <td>[0.0584415584416, 0.792207792208, 0.1493506493...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3.0, 1.0, 3.0, 2.0, 2.0, 0.0]</td>\n",
       "      <td>[9.0, 122.0, 23.0, 0.0]</td>\n",
       "      <td>[0.0584415584416, 0.792207792208, 0.1493506493...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.0, 2.0, 1.0, 0.0, 0.0, 2.0]</td>\n",
       "      <td>[504.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.0, 2.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[504.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.0, 2.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[504.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying maint  doors persons lug_boot safety acceptability  buying_ix  \\\n",
       "0     low  high  5more       4      big    low         unacc        3.0   \n",
       "1     low  high  5more       4      big    med           acc        3.0   \n",
       "2     low  high  5more       4      big   high         vgood        3.0   \n",
       "3     low  high  5more    more    small    low         unacc        3.0   \n",
       "4     low  high  5more    more    small    med           acc        3.0   \n",
       "5     low  high  5more    more    small   high           acc        3.0   \n",
       "6     low  high  5more    more      med    low         unacc        3.0   \n",
       "7     low  high  5more    more      med    med           acc        3.0   \n",
       "8     low  high  5more    more      med   high         vgood        3.0   \n",
       "9     low  high  5more    more      big    low         unacc        3.0   \n",
       "10    low  high  5more    more      big    med           acc        3.0   \n",
       "11    low  high  5more    more      big   high         vgood        3.0   \n",
       "12    low   med      2       2    small    low         unacc        3.0   \n",
       "13    low   med      2       2    small    med         unacc        3.0   \n",
       "14    low   med      2       2    small   high         unacc        3.0   \n",
       "\n",
       "    maint_ix  doors_ix  persons_ix  lug_boot_ix  safety_ix  acceptability_ix  \\\n",
       "0        1.0       3.0         1.0          2.0        2.0               0.0   \n",
       "1        1.0       3.0         1.0          2.0        1.0               1.0   \n",
       "2        1.0       3.0         1.0          2.0        0.0               2.0   \n",
       "3        1.0       3.0         2.0          0.0        2.0               0.0   \n",
       "4        1.0       3.0         2.0          0.0        1.0               1.0   \n",
       "5        1.0       3.0         2.0          0.0        0.0               1.0   \n",
       "6        1.0       3.0         2.0          1.0        2.0               0.0   \n",
       "7        1.0       3.0         2.0          1.0        1.0               1.0   \n",
       "8        1.0       3.0         2.0          1.0        0.0               2.0   \n",
       "9        1.0       3.0         2.0          2.0        2.0               0.0   \n",
       "10       1.0       3.0         2.0          2.0        1.0               1.0   \n",
       "11       1.0       3.0         2.0          2.0        0.0               2.0   \n",
       "12       2.0       1.0         0.0          0.0        2.0               0.0   \n",
       "13       2.0       1.0         0.0          0.0        1.0               0.0   \n",
       "14       2.0       1.0         0.0          0.0        0.0               0.0   \n",
       "\n",
       "                          features            rawPrediction  \\\n",
       "0   [3.0, 1.0, 3.0, 1.0, 2.0, 2.0]   [332.0, 0.0, 0.0, 0.0]   \n",
       "1   [3.0, 1.0, 3.0, 1.0, 2.0, 1.0]  [9.0, 122.0, 23.0, 0.0]   \n",
       "2   [3.0, 1.0, 3.0, 1.0, 2.0, 0.0]  [9.0, 122.0, 23.0, 0.0]   \n",
       "3   [3.0, 1.0, 3.0, 2.0, 0.0, 2.0]   [332.0, 0.0, 0.0, 0.0]   \n",
       "4   [3.0, 1.0, 3.0, 2.0, 0.0, 1.0]   [31.0, 47.0, 0.0, 0.0]   \n",
       "5   [3.0, 1.0, 3.0, 2.0, 0.0, 0.0]   [31.0, 47.0, 0.0, 0.0]   \n",
       "6   [3.0, 1.0, 3.0, 2.0, 1.0, 2.0]   [332.0, 0.0, 0.0, 0.0]   \n",
       "7   [3.0, 1.0, 3.0, 2.0, 1.0, 1.0]  [9.0, 122.0, 23.0, 0.0]   \n",
       "8   [3.0, 1.0, 3.0, 2.0, 1.0, 0.0]  [9.0, 122.0, 23.0, 0.0]   \n",
       "9   [3.0, 1.0, 3.0, 2.0, 2.0, 2.0]   [332.0, 0.0, 0.0, 0.0]   \n",
       "10  [3.0, 1.0, 3.0, 2.0, 2.0, 1.0]  [9.0, 122.0, 23.0, 0.0]   \n",
       "11  [3.0, 1.0, 3.0, 2.0, 2.0, 0.0]  [9.0, 122.0, 23.0, 0.0]   \n",
       "12  [3.0, 2.0, 1.0, 0.0, 0.0, 2.0]   [504.0, 0.0, 0.0, 0.0]   \n",
       "13  [3.0, 2.0, 1.0, 0.0, 0.0, 1.0]   [504.0, 0.0, 0.0, 0.0]   \n",
       "14  [3.0, 2.0, 1.0, 0.0, 0.0, 0.0]   [504.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                          probability  prediction  \n",
       "0                                [1.0, 0.0, 0.0, 0.0]         0.0  \n",
       "1   [0.0584415584416, 0.792207792208, 0.1493506493...         1.0  \n",
       "2   [0.0584415584416, 0.792207792208, 0.1493506493...         1.0  \n",
       "3                                [1.0, 0.0, 0.0, 0.0]         0.0  \n",
       "4          [0.397435897436, 0.602564102564, 0.0, 0.0]         1.0  \n",
       "5          [0.397435897436, 0.602564102564, 0.0, 0.0]         1.0  \n",
       "6                                [1.0, 0.0, 0.0, 0.0]         0.0  \n",
       "7   [0.0584415584416, 0.792207792208, 0.1493506493...         1.0  \n",
       "8   [0.0584415584416, 0.792207792208, 0.1493506493...         1.0  \n",
       "9                                [1.0, 0.0, 0.0, 0.0]         0.0  \n",
       "10  [0.0584415584416, 0.792207792208, 0.1493506493...         1.0  \n",
       "11  [0.0584415584416, 0.792207792208, 0.1493506493...         1.0  \n",
       "12                               [1.0, 0.0, 0.0, 0.0]         0.0  \n",
       "13                               [1.0, 0.0, 0.0, 0.0]         0.0  \n",
       "14                               [1.0, 0.0, 0.0, 0.0]         0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceptability</th>\n",
       "      <th>acceptability_ix</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unacc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgood</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unacc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unacc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgood</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unacc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgood</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unacc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>unacc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unacc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acceptability  acceptability_ix  prediction\n",
       "0          unacc               0.0         0.0\n",
       "1            acc               1.0         1.0\n",
       "2          vgood               2.0         1.0\n",
       "3          unacc               0.0         0.0\n",
       "4            acc               1.0         1.0\n",
       "5            acc               1.0         1.0\n",
       "6          unacc               0.0         0.0\n",
       "7            acc               1.0         1.0\n",
       "8          vgood               2.0         1.0\n",
       "9          unacc               0.0         0.0\n",
       "10           acc               1.0         1.0\n",
       "11         vgood               2.0         1.0\n",
       "12         unacc               0.0         0.0\n",
       "13         unacc               0.0         0.0\n",
       "14         unacc               0.0         0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.select(\"acceptability\", \"acceptability_ix\", \"prediction\").limit(15).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13\\. Using `MulticlassClassificationEvaluator` to evaluate the predictions on the `accuracy` metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='acceptability_ix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7236842105263158"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.evaluate(predictions,{e.metricName: \"accuracy\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
