{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Lab 4: Use Pair RDDs to join two datasets (Solution)\n",
    "\n",
    "Data used in this lab:\n",
    "- weblog data: `/home/cloudera/training_materials/data/weblogs/`\n",
    "- user accounts data: `/home/cloudera/training_materials/data/static_data/accounts/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: In this lab you will be reducing and joining large datasets, which can take a lot of time. You may wish to perform the exercises below using a smaller dataset, consisting of only one of the many web log files, rather than all of them. For example, one of the web log file is **`2013-09-15.log`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Web Log Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following python function parse a log line into a tuple using regular expression. You can use this later on for log line pasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "def parse_log_line(line):\n",
    "    pattern = '^([\\d.]+) - (\\d+) \\[(.+?)\\] \\\"(.+?)\\\" (\\d{3}) (\\d+) \\\"(.+?)\\\"  \\\"(.+)\\\"';\n",
    "    try:\n",
    "        match = re.search(pattern,line)\n",
    "        return (match.group(1),match.group(2),match.group(3),match.group(4), \\\n",
    "            match.group(5),match.group(6),match.group(7),match.group(8))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load and parse data data\n",
    "Load the data from the weblog data location and parse it with the provided `parse_log_line` function.\n",
    "- Please read just one file **2013-09-15.log** in the testing period. After you're done testing, you can load the entire dataset, which may be time-consuming to process. \n",
    "- You can cache the data for later reuse using `.cache()`, so that you don't have to reload and repharse in each step of the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs = sc.textFile(\"file:/home/cloudera/training_materials/data/weblogs/2013-09-15.log\").map(parse_log_line).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'3.94.78.5', u'69827', u'15/Sep/2013:23:58:36 +0100', u'GET /KBDOC-00033.html HTTP/1.0', u'200', u'14417', u'http://www.loudacre.com', u'Loudacre Mobile Browser iFruit 1')\n",
      "(u'3.94.78.5', u'69827', u'15/Sep/2013:23:58:36 +0100', u'GET /theme.css HTTP/1.0', u'200', u'3576', u'http://www.loudacre.com', u'Loudacre Mobile Browser iFruit 1')\n"
     ]
    }
   ],
   "source": [
    "# print some samples to verify the result\n",
    "for row in logs.take(2):\n",
    "    print row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Using map-reduce to count the number of requests from each user\n",
    "\n",
    "- Use map and to create a Pair RDD with the user ID as the key, and the integer 1 as the value. (The user ID is the second field in each line.) After mapping, your data will look something like this:\n",
    "```\n",
    "(userid,1) \n",
    "(userid,1) \n",
    "(userid,1)\n",
    "```\n",
    "- Use reduceByKey to sum the values for each user ID. Your RDD data will be similar to:\n",
    "```\n",
    "(userid1,5) \n",
    "(userid2,7) \n",
    "(userid3,2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userCount = logs.map(lambda row:(row[1],1)).reduceByKey(lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use type function to verify the type of the variable\n",
    "type(userCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60988,4\n",
      "45741,2\n",
      "53488,4\n",
      "58228,4\n",
      "63239,2\n"
     ]
    }
   ],
   "source": [
    "# print the outcome in formatted fasion\n",
    "for row in userCount.take(5):\n",
    "    print(\"{},{}\".format(*row))  # the operator * unpack the elements in the `row` tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Determine how many users visited the site for each frequency (histogram) \n",
    "Determine how many users visited the site for each frequency. That is, how many users visited once, twice, three times and so on.\n",
    "- Use `map` to reverse the key and value, like this:\n",
    "```\n",
    "(5,userid)\n",
    "(7,userid)\n",
    "(2,userid)\n",
    "```\n",
    "- Use the `countByKey` action to return a Map of `frequency:user-count` pairs, such as:\n",
    "```\n",
    "(5,10)\n",
    "(7,50)\n",
    "(2,100)\n",
    "```\n",
    "- save the result in variable `freqCount`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "freqCount = userCount.map(lambda (user,cnt):(cnt,user)) \\\n",
    "    .countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determine the type of the variable `freqCount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(freqCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the outcome in the formatted fashion like this:\n",
    "```\n",
    "1:25\n",
    "2:32\n",
    "3:44\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:757\n",
      "3:2\n",
      "4:302\n",
      "6:62\n",
      "8:27\n",
      "10:10\n",
      "12:2\n"
     ]
    }
   ],
   "source": [
    "for item in freqCount.items():\n",
    "    print(\"{}:{}\".format(*item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Build an IP address list for each user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Frist build a list of `<user_id, ip>` pairs sorted by user id\n",
    "- Create an RDD where the user id is the key, and the value is the IP addresses that user has connected from. (IP address is the first field in each request line.)\n",
    "- Sort result by userid\n",
    "- Save result in **`userIpSorted`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userIpSorted = logs.map(lambda row:(row[1],row[0])) \\\n",
    "    .sortByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the first 10 outcome in the form of `userid<tab>ip_address`, such as:\n",
    "```\n",
    "1         127.0.0.1\n",
    "123       127.0.0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t225.237.182.117\n",
      "1\t225.237.182.117\n",
      "100\t187.142.238.101\n",
      "100\t187.142.238.101\n",
      "100\t208.253.247.9\n",
      "100\t208.253.247.9\n",
      "10022\t6.46.42.13\n",
      "10022\t6.46.42.13\n",
      "10022\t6.46.42.13\n",
      "10022\t6.46.42.13\n"
     ]
    }
   ],
   "source": [
    "for item in userIpSorted.take(10):\n",
    "    print(\"{}\\t{}\".format(*item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create an RDD where the user id is the key, and the value is the list of all the IP addresses that user has connected from. \n",
    "- Hint: Map to (userid,ip_address) and then use **`groupByKey`**\n",
    "- Hint: **`groupByKey`** return a pyspark iterable object, you can convert it to a list using **`mapValues`** with a type conversion function: **`list()`**\n",
    "- Save results in **userIpList**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userIpList = logs.map(lambda row:(row[1],row[0])) \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the first five result as tab delimited rows, such as:\n",
    "```\n",
    "123    [ip_1, ip_2, ...]\n",
    "2334   [ip_1, ip_4]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60988\t[u'248.254.226.12', u'248.254.226.12', u'248.254.226.12', u'248.254.226.12']\n",
      "45741\t[u'75.226.179.34', u'75.226.179.34']\n",
      "53488\t[u'52.101.213.105', u'52.101.213.105', u'52.101.213.105', u'52.101.213.105']\n",
      "58228\t[u'135.41.174.97', u'135.41.174.97', u'135.41.174.97', u'135.41.174.97']\n",
      "63239\t[u'240.193.143.197', u'240.193.143.197']\n"
     ]
    }
   ],
   "source": [
    "for item in userIpList.take(5):\n",
    "    print(\"{}\\t{}\".format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Create an RDD where the user id is the key, and the value is the *distinct* list of all the IP addresses that user has connected from. \n",
    "- Similar to B, but now we want a distinct list of values, consider using **set** instead of list\n",
    "- Save results to **userIpListDistinct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userIpListDistinct = logs.map(lambda row:(row[1],row[0])) \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the first five result as tab delimited rows, such as:\n",
    "```\n",
    "123    [ip_1, ip_2, ...]\n",
    "2334   [ip_1, ip_4]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60988\t[u'248.254.226.12']\n",
      "45741\t[u'75.226.179.34']\n",
      "53488\t[u'52.101.213.105']\n",
      "58228\t[u'135.41.174.97']\n",
      "63239\t[u'240.193.143.197']\n"
     ]
    }
   ],
   "source": [
    "for item in userIpListDistinct.take(5):\n",
    "    print(\"{}\\t{}\".format(item[0],list(item[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Web Log Data with Account Data\n",
    "\n",
    "The accounts data (located in /home/cloudera/training_materials/data/static_data/accounts/). Sample rows look like this:\n",
    "```\n",
    "1,2008-10-23 16:05:05.0,\\N,Donald,Becton,2275 Washburn Street,Oakland,CA,94660,5100032418,2014-03-18 13:29:47.0,2014-03-18 13:29:47.0\n",
    "2,2008-11-12 03:00:01.0,\\N,Donna,Jones,3885 Elliott Street,San Francisco,CA,94171,4150835799,2014-03-18 13:29:47.0,2014-03-18 13:29:47.0\n",
    "3,2008-12-21 09:19:50.0,\\N,Dorthy,Chalmers,4073 Whaley Lane,San Mateo,CA,94479,6506877757,2014-03-18 13:29:47.0,2014-03-18 13:29:47.0\n",
    "```\n",
    "- The first field in each line is the user ID, which corresponds to the user ID in the web server logs. \n",
    "- The other fields include account details such as creation date, first and last name and so on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load and parse data data\n",
    "- Load the data from the account data location and parse it.\n",
    "- Cache the data for later reuse\n",
    "- Save result in **accounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts = sc.textFile(\"file:/home/cloudera/training_materials/data/static_data/accounts/*\") \\\n",
    "    .map(lambda line:line.split(',')) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- verify result by printing the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'1',\n",
       "  u'2008-10-23 16:05:05.0',\n",
       "  u'\\\\N',\n",
       "  u'Donald',\n",
       "  u'Becton',\n",
       "  u'2275 Washburn Street',\n",
       "  u'Oakland',\n",
       "  u'CA',\n",
       "  u'94660',\n",
       "  u'5100032418',\n",
       "  u'2014-03-18 13:29:47.0',\n",
       "  u'2014-03-18 13:29:47.0']]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Join the accounts data with userCount data. \n",
    "The goal of this step is to produce a dataset with userid, hitcount, and name. In order to do this, we need to \n",
    "- Create an RDD based on the accounts data consisting of key/value pairs such as:\n",
    "```\n",
    "(userid1,[userid1,2008-11-24 10:04:08,\\N,Cheryl,West,4905 Olive Street,San Francisco,CA,…])\n",
    "(userid2,[userid2,2008-11-23 14:05:07,\\N,Elizabeth,Kerns,4703 Eva Pearl Street,Richmond,CA,…])\n",
    "(userid3,[userid3,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa,Roman,3539 James Martin Circle,…])\n",
    "```\n",
    "- Join the Pair RDD with the set of userCount pair RDD calculated in the first section.\n",
    "```\n",
    "(userid1,([userid1,2008-11-24 10:04:08,\\N,Cheryl,West,4905 Olive Street,San Francisco,CA,…], 3))\n",
    "(userid2,([userid2,2008-11-23 14:05:07,\\N,Elizabeth,Kerns,4703 Eva Pearl Street,Richmond,CA,…], 8))\n",
    "(userid3,([userid3,2008-11-02 17:12:12,2013-07-18 16:42:36,Melissa,Roman,3539 James Martin Circle,…], 10))\n",
    "```\n",
    "- Save results in **joined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined = accounts.keyBy(lambda row:row[0]) \\\n",
    "    .join(userCount) \\\n",
    "    .map(lambda (userid,(row,count)):(userid, count,row[3]+' '+row[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verify results by print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'25062', 2, u'Cynthia Anderson'),\n",
       " (u'57298', 2, u'Judith Caballero'),\n",
       " (u'9256', 2, u'Brett King'),\n",
       " (u'623', 2, u'Anthony Valenzuela'),\n",
       " (u'72369', 4, u'Evelyn Simmons')]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Create a list of names by Postal Code\n",
    "- Use **keyBy** to create an RDD of account data with the postal code (9th field in the CSV data) as the key\n",
    "- Convert the RDD to a new RDD with postal code as the key and a list of names (Last Name,First Name) in that postal code as the value.\n",
    "    - Hint: First name and last name are the 4th and 5th fields respectively\n",
    "- Save results in **postalRoster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postalRoster = accounts.keyBy(lambda row:row[8]) \\\n",
    "    .mapValues(lambda row:(row[3],row[4])) \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(lambda names:list(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take the first five postal codes sorted by postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first5postal = postalRoster.takeOrdered(5,lambda (postal,names):postal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Display the names for the first five postal codes in the following format, e.g. \n",
    "```\n",
    "--- 85003\n",
    "Jenkins, Thad \n",
    "Rick, Edward \n",
    "Lindsay, Ivy\n",
    "...\n",
    "--- 85004\n",
    "Morris, Eric \n",
    "Reiser, Hazel \n",
    "Gregg, Alicia \n",
    "Preston, Elizabeth\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 85000\n",
      "Allen, Harvey\n",
      "Prinz, Daniel\n",
      "Pascale, Robert\n",
      "Brookes, Donna\n",
      "Mackenzie, James\n",
      "Chamberlain, Robert\n",
      "Cunningham, Richard\n",
      "Sewell, Bailey\n",
      "Marin, Daniel\n",
      "--- 85001\n",
      "Mendelsohn, Frances\n",
      "Watson, Mary\n",
      "Brookover, Donald\n",
      "Hathaway, Brandon\n",
      "Leonard, Crystal\n",
      "Moran, Carrie\n",
      "Kirksey, Marie\n",
      "Lance, Issac\n",
      "Barnes, Vesta\n",
      "Fiore, Eva\n",
      "Tucker, Keith\n",
      "Medford, Danielle\n",
      "Spell, Norman\n",
      "Soto, Shelley\n",
      "Frantz, Kathy\n",
      "Wilkins, Timothy\n",
      "Snyder, Joseph\n",
      "Flores, Delbert\n",
      "Eakes, Gail\n",
      "Daniels, Bert\n",
      "Carpenter, Vincent\n",
      "--- 85002\n",
      "Whitney, Ruby\n",
      "Perry, David\n",
      "James, Marianne\n",
      "Holiman, Nancy\n",
      "Roman, Allen\n",
      "Manus, Donna\n",
      "Reed, Nancy\n",
      "Baird, Estella\n",
      "Gilbert, James\n",
      "McKay, David\n",
      "Clark, Laura\n",
      "Horn, John\n",
      "Payne, Jessica\n",
      "Stewart, Bryant\n",
      "Jones, Jose\n",
      "Robinson, Wesley\n",
      "--- 85003\n",
      "Martin, Mark\n",
      "Ross, Vivian\n",
      "Tabor, Harry\n",
      "Strickland, Kyle\n",
      "Dvorak, Kevin\n",
      "Wisniewski, Virginia\n",
      "Gibson, Catherine\n",
      "Thies, Lindsey\n",
      "--- 85004\n",
      "Kitts, Mary\n",
      "Viola, Kevin\n",
      "Meadows, Tonya\n",
      "Royalty, Sherry\n",
      "Collins, Greg\n",
      "Shirley, Joseph\n",
      "White, Sandra\n",
      "Stern, Timothy\n",
      "Johnson, Dominic\n",
      "Dewitt, Mary\n",
      "Carpenter, Matthew\n",
      "Ball, Annie\n",
      "Pate, Kathleen\n",
      "Lish, Carrie\n"
     ]
    }
   ],
   "source": [
    "for row in first5postal:\n",
    "    print(\"--- {}\".format(row[0]))\n",
    "    for name in row[1]:\n",
    "        print(\"{}, {}\".format(name[1],name[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
